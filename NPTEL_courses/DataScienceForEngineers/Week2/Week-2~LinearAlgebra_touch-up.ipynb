{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea2e442-1edd-4127-8bdd-fcc5ed07c98c",
   "metadata": {
    "tags": []
   },
   "source": [
    "let's start with a question..\n",
    "## What linear algebra is useful for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a4f5b-cec1-4a62-bd01-36e45e95f2e4",
   "metadata": {},
   "source": [
    "*(When one talks about data science..)*\n",
    "\n",
    "1. **Data representation** becomes an important aspect.\n",
    "    - Data is represented in a matrix form. _So, we talk about this representation and concepts_.\n",
    "2. _(In the data science perspective..)_ If the data contains several variables of interest, one might want to know **How many of these variables are really important?**, and **If there are any relationships, how can one uncover those?**\n",
    "3. The ideas from linear algebra becomes fundamental concept in Machine Learning Algorithms.\n",
    "\n",
    "these important questions are answered by the Linear Algebra.\n",
    "\n",
    "![Linear algebra in Data science](resources/LinearAlgebra_in_DataScience.png)\n",
    "\n",
    "Each of the above is addressed in further notes.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e381b-9a30-4379-a356-8f200f4d7535",
   "metadata": {},
   "source": [
    "Let's start with the matrices.. and summarize the points which are relevant to the data science perspective\n",
    "**What is a matrix?**\n",
    "> A matrix is a form of organizing data into rows and columns.\n",
    "\n",
    "There are many ways of representing the data, matrix provides a convinient way..\n",
    "- If you are an engineer, and you deal with multiple variables, how do you store them so that you can use later?\n",
    "- Matrices can also be used to store the coefficients of the equations\n",
    "\n",
    "![Matrix Theory and Linear algebra](resources/MatrixTheoryAndLinearAlgebra.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb4ec3-b178-4e17-8b88-3b43c4c6fd6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Representation: Examples\n",
    "    \n",
    "![Data Representation-Examples](resources/DataRepresentation-Examples.png)\n",
    "each row is a sample data.\n",
    "\n",
    "A vector of attibutes..\n",
    "\n",
    "![](resources/DataRepresentation-Examples2.png)\n",
    "\n",
    "Storing images..\n",
    "\n",
    "![](resources/DataRepresentation-Examples3.png)\n",
    "\n",
    "and answering, whether two images same or identify the sub-components in the image..... all of these can be performed through some form of matrix manipulation.\n",
    "\n",
    "Data as matrix - Summary\n",
    "    \n",
    "![](resources/DataAsMatrix-Summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cff092-d1bf-4d09-a649-03d41ae312af",
   "metadata": {},
   "source": [
    "now coming to the second aspect..\n",
    "\n",
    "## Identification of Idependent attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768b4da-83fe-47f4-97ed-2d9308d3d6ca",
   "metadata": {},
   "source": [
    "* One might be interested in knowing, if all the variables that **are there are imporant?**\n",
    "_(in other words..)_\n",
    "* In all these variables, **how many of these are independent?**, so that, if contains (say) 1000's of variables and there are 4-5 independent variables, then one can store these variables and calculate the remaining as a function of these variables.\n",
    "\n",
    "These lead to the following questions..\n",
    "![](resources/FurtherAnalysis.png)\n",
    "\n",
    "If could find those independent variables, can drop the remaining. --- This is an important aspect in Machine Learning.\n",
    "\n",
    "![](resources/IdentificationOfIndependentAttributes-Example.png)\n",
    "![](resources/IdentificationOfIndependentAttributes-Example1.png.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e92be-1e3f-4452-8f75-ce263ba3e592",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### How can one identify the independent attributes? - Rank of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c398c8-914d-46c6-9c8d-0710644178fb",
   "metadata": {},
   "source": [
    "![](resources/NumberOfIndependentAttributes-Rank.png)\n",
    "\n",
    "Rank of matrix:\n",
    "> Number of linearly independent rows or columns in a matrix.\n",
    "  Denoted as `rank(A)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c17600-605f-440a-bbcd-04cc1a11c16f",
   "metadata": {},
   "source": [
    "See, the below matrix, its deliberately generated in such a way that, column-2 depends on column-1.\n",
    "![](resources/NumberOfIndependentAttributes-Rank1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe2353-9ace-4ecc-b5d7-9b169b693a98",
   "metadata": {},
   "source": [
    "## Rank: Advantages and summary\n",
    "![](resources/Rank-AdvantagesAndSummary.png)\n",
    "\n",
    "ok, now we come to know the **no. of indpendent variables, but how about the relationship with the dependent variables...??** _--this further motivates as ..._\n",
    "\n",
    "## Identification of Linear relationships among attributes - _via concept of **Null Space** and **Nullity**_\n",
    "\n",
    "**NullSpace of a matrix**\n",
    "> The null space of a matrix $A$ consists of all vectors $\\beta$, such that $A\\beta\\ = \\ 0$ and $\\beta \\ = \\ 0$. Then $\\beta$ is called the null space of the matrix.\n",
    ">> **What does $A\\beta\\ = \\ 0$ mean?**\n",
    " _its addressed in the next section formally. (intuitively explained in the below slide picture).._\n",
    "\n",
    "Interestingly, **the size of the null space of a matrix provides us the _no. of linear relations_ among the attributes.**\n",
    "> i.e., if a matrix having dimensions 5, then if we got a null space matrix's size as `2`, then it implies that `5-2=3` are linearly independent._(The other two depend on these, so got nullified)_.\n",
    "\n",
    "**Nullity of a matrix**\n",
    "> Number of vectors in the null space of the given matrix -- _(from understanding [Please correct if not]..it tells **no. of dependent variables in the matrix**)_\n",
    "\n",
    "![](resources/NullSpaceAndNullity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabae71-61c8-4542-9c38-f82374c7ded1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NullSpace: General Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b30fe4-43e1-4b24-9c4b-d27054a1db0a",
   "metadata": {},
   "source": [
    "![](resources/NullSpace-GeneralDescription.png)\n",
    "\n",
    "those equations denote the $A\\beta\\ = \\ 0$.. hope not got clear..!! _(Referred from the dobut in above cell)_\n",
    "- and the generic form is written above all the equations in the red-ink. It can be interpreted as..\n",
    "> Where you can take any sample and substitute the values of variables in that $x_1,\\ x_2,...x_n$, and this is to be satisfied, its a true relationship.\n",
    "\n",
    "formally..\n",
    "![](resources/NullSpace-TheIDEA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c3556-0b99-4e73-a94f-14750ea0c5c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "It can be demonstrated as..\n",
    "![Rank Nullity theorem](resources/RankNullityTheorem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607526c4-41b6-4d7b-bfe0-336100c5541b",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Why _\"Nullity of A\"_ means _\"Number of equations\"_?**\n",
    "Think..!!\n",
    "> What does Nullity of A tells? _(from understanding, please correct if not)_ it tells the no of dependent variables. So, how can we get those back after dropped, via independent variables? -- via equation right..??. So, if had $n$ no. of dependent variables, then we need same $n$ no. of equations to get those right..??\n",
    "\n",
    "NOTE: -- its purely based on understanding, by grace. Correct if found to be incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb87678-7ab3-4bc1-9ddc-f7f3ba98174c",
   "metadata": {},
   "source": [
    "### Summary\n",
    "![](resources/NullSpaceSummary.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896c0e2-5d94-4a48-a742-c0f3f0f6dbb0",
   "metadata": {},
   "source": [
    "![](resources/NullSpace-AnExample.png)\n",
    "![](resources/NullSpace-AnExample1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee73752-61b7-4b89-bd2f-89bb93383b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](resources/NullSpace-FurtherExample.png) -- Need workout on this.\n",
    "* R1's clear..\n",
    "* The 2nd row's equation was dropped, as its the multiple of R1.\n",
    "* R3's, how about 3 and 6..?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f361b78-572e-45b0-9e5c-a993c952ee20",
   "metadata": {},
   "source": [
    "### Overall Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7eb0f-fd53-4be9-ac49-289afd3bbf9c",
   "metadata": {},
   "source": [
    "![](resources/OverallSummary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7af030-7165-4bcd-96a9-b7cdc5fb652f",
   "metadata": {},
   "source": [
    "****\n",
    "End of Module-1\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a309d-4f43-432e-ae7a-3d89749e5c8c",
   "metadata": {},
   "source": [
    "# Module-2: **Solving Linear Equations**\n",
    "    -- on 24th August, 2021 ~ Tuesday_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a00d95-16f2-43e8-8f15-eeb7ed16fb9c",
   "metadata": {},
   "source": [
    "Recap..\n",
    "![Recap](resources/Recap-SolvingLinearEquations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc6e78-7bac-419d-bae6-3cbb250773db",
   "metadata": {},
   "source": [
    "### Solving Matrix Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09246da8-1a70-489e-aa9a-b8902bf89fb8",
   "metadata": {},
   "source": [
    "Recollect..!! from the M-I of Diploma Math, Smt. Gomati Madam has taught the subject..\n",
    "\n",
    "![Preliminaries](resources/Preliminaries.png)\n",
    "\n",
    "Categorization..\n",
    "\n",
    "![Categorization](resources/Categorization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bcb27-a77c-463a-9f2e-b18839930662",
   "metadata": {},
   "source": [
    "A short note on Ranks.. _(as they are going to be used here..)_\n",
    "\n",
    "![](resources/FullRow&ColumnRank-Concepts.png)\n",
    "\n",
    "* Generally, if had a matrix $A_{mxn}$, then... maximum rank value can be atmost $m$ if $m<n$, else $n$ if $n<m$.-- i.e., the smallest value in dimensions of the matrix, is the maximum value, a rank can be.\n",
    "* Generally, whatever may be the size of the matrix, **Row Rank = column Rank**  _-- indicates that, if had certain no. of independent rows, then we have same no. of independent no, of cols_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a597528-562d-47aa-9b91-06a0345d1372",
   "metadata": {},
   "source": [
    "**P2N:** rank tells the no. of independent cols (or rows)\n",
    "\n",
    "Case-1: `m==n`\n",
    "* If A is full rank (Now the max rank can be either m or n, as m==n), then\n",
    "    * We have all the rows or cols independent of each other _(in other words)_, we don't get any row or column such that [On LHS], its being linearly dependent on other. 00 then we have **Unique solution**, its $x=A^{-1}b$ -- How..?? as the equation is of the form $Ax = b$, and we need $x$, so by simply transposing $A$ to R.H.S. ... we get that..\n",
    "* The difficulty arises here.. think why the rank is less... on L.H.S. atleast one row or col, linearly depends on other. In this case, depending on what value we have on the R.H.S. we have 2 cases.. \n",
    "    * One is **Consistent** situation -- Will have many solutions..\n",
    "    * Second is **Inconsistent** - no solution\n",
    "    \n",
    "![](resources/1stcase.png)\n",
    "\n",
    "Example: With Full rank.  -- demonstrating the _Unique solution_\n",
    "\n",
    "![](resources/case1Example.png)\n",
    "--- P2N: No other solution, can satisfy the equation.-- as it is the unique solution.\n",
    "****\n",
    "\n",
    "Example: With < full rank... -- demonstarting the _Consistent solution_\n",
    "* Notice that, they are linearly dependent -- both column-wise and row-wise. -- its even said by _rank_ and _determinant being=0_.\n",
    "* We generally consider the LHS.\n",
    "\n",
    "![](resources/case1Example1.png)\n",
    "* Also notice that, <mark>even the R.H.S. is also linearly dependent.</mark> It means that, we can calculate the one and get the other. **NOTICE** that, we get the freedom to choose $x_1$ or $x_2$ (satisifying the left-over equation ofcourse..). \n",
    "\n",
    "**What is meant by having infinite no. of solutions?**\n",
    "> See that, We have infinite choice of choosing the $x_1$ or $x_2$ (one keeping fixed) and all those infinite choices are valid for the equation. Hence, we get the infinite no. of solutions.\n",
    "\n",
    "****\n",
    "Example: with < full rank -- demonstrating the _Inconsistent solutions_.\n",
    "* Its same as above example, with a change that, RHS is not linearly dependent -- _Still the L.H.S. is linearly dependent_\n",
    "\n",
    "![](resources/case1Exampl3.png)\n",
    "\n",
    "**Why the solution is not possible?**\n",
    "> as whatever values that we choose for $X_1$ and $x_2$ and plug those to the equations -- 1st satisfies, whereas for 2nd it yields 10, but need 9, which is never possible. Hence the solution is not possible.\n",
    "    *  In other words, if that number is other than 10, the solution is not possible.\n",
    "    \n",
    "**<mark>P2N</mark>**: We get inconsistent solution, only when $rank<fullRank$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95f57b-86c0-4e2d-91f9-06493504def3",
   "metadata": {},
   "source": [
    "### **Case-2: $m>n$**\n",
    "![](resources/case2.png)\n",
    "* Even though some times, its termed as no-solutions case -- from an optimization perspective can try..\n",
    "\n",
    "![](resources/case2AnOptimizationPerspective1.png) means..\n",
    "\n",
    "* When had ![](resources/case2AnOptimizationPerspective1.1.png) perfect solutions for all the three equations _(i., the values for which $x_1, x_2, x_3$ satisfies)_. Then can write as![](resources/case2AnOptimizationPerspective1.2.png).\n",
    "* But, whenever we don't have the perfect solution, let's call it error. And we allowed it, so we get 3 (or as many depending on equations) different errors right.. It's represented as ![](resources/case2AnOptimizationPerspective1.3.png) -  in slide represented as ![](resources/case2AnOptimizationPerspective1.4.png)\n",
    "\n",
    "**How do we minimize the errors collectively?**\n",
    "* One might say that **sum up all those**, but that won't be a good idea as, $e_1$ could be a vey big error in +ve direction, and $e_2$ could be a -ve direction which may sum up to 0, and e_3.. --- that's not a good solution at all.\n",
    "* One way to do is, **Collectively minimize the error** ![](resources/case2AnOptimizationPerspective1.5.png). i.e., Instead of going $e_1 + e_2 + e_3$, can go as $e_1^2 + e_2^2 + e_3^2$---- As long as these ($e_1, e_2, e_3$) are away from 0, the contribution to error is high. _(as squaring right..!!)_ -- that ensures that, you do not go far away from 0. -- this is the **<mark>Least Square Solution</mark>**. \n",
    "* Can also try as $|e_1| + |e_2| + |e_3|$ _(as $|$ always gives +ve)_ -- that's also possible, but in general we consider this method.\n",
    "\n",
    "* Notice that, one can write this($e_1^2 + e_2^2 + e_3^2$ ) also as $e^Te$ which is equivalent to ![](resources/case2AnOptimizationPerspective1.6.png)\n",
    "****\n",
    "To put it together..\n",
    "![](resources/case2AnOptimizationPerspecive.png)\n",
    "\n",
    "****\n",
    "![](resources/case2AnOptimizationPerspective1.7.png) -- The top-centered final equation is obtained *after some algebraic manipulation* -- that's what sir, said about it. You please work out on it.\n",
    "\n",
    "![](resources/case2AnOptimizationPerspective1.8.png) -- the final solution $x$, might not satisfy for all the values of equations, it ensures that, error is collectively minimized.  \n",
    "\n",
    "**** \n",
    "Concludes the lecture, in the next lecture..\n",
    "* An ex. to illustrate how these are satisfied or not satisfied. Next case-3 where m>n.\n",
    "* Next, how can these can be combined into one elegant solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ee1bc-2935-4c96-ac4e-6f82562340aa",
   "metadata": {},
   "source": [
    "## Module-3\n",
    "--- on 2nd September, 2021 ~ Thursday (Ekadashi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215374f3-bf4f-4a50-811f-f75ee282ab76",
   "metadata": {},
   "source": [
    "![](resources/case2-OptimzationExample-1_1.png)\n",
    "* You can observe that the first 2 equations are inconsistent. i.e., $1x_1 = 1$....`#1` and $2x_2=-0.5$......`#2`, think here.. by what value can you satisfy these two combinely? -- that isn't possible, hence its incosistent.  \n",
    "* Coming to the $3x_1+x_2=5$........`#x3`, by fixing $x_1$, can get $x_2$.\n",
    "\n",
    "On the whole, this is not solvable.\n",
    "****\n",
    "Then, how do we solve these..?? --- via **Optimization concept** : $x = (A^TA)^{-1}A^Tb$ ............... as discussed in previous lecture *(Refer to the prev-lecture notes)*\n",
    "![](resources/case2-OptimzationExample-1_2.png)\n",
    "![](resources/case2-OptimzationExample-1_3.png)\n",
    "**** \n",
    "Workout part...![](resources/DataScienceForEngineers_Week_2-SolvingLinearEquations_case_2-Module_3-ExamplesWorkout_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b214621-c6bf-46fc-a61c-ffb660d48e4c",
   "metadata": {},
   "source": [
    "![](resources/case2-OptimzationExample-2_1.png)\n",
    "![](resources/case2-OptimzationExample-2_2.png)\n",
    "![](resources/DataScienceForEngineers_Week_2-SolvingLinearEquations_case_2-Module_3-ExamplesWorkout_2.jpg)\n",
    "\n",
    "<h3><mark>P2N></mark></h3>: If we have more equations that variables, then can use the least square solution ($x = (A^TA)^{-1}A^Tb$). And the important point to be noted here is that: <mark>$A^TA$ exists, if the columns of $A$ are linearly independent</mark>.\n",
    "\n",
    "If not independent, need to go with another approach -- discussed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9b2522-1ac0-4267-8b8f-7814127ec7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>2</td><td>0</td></tr>\n",
       "\t<tr><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t 1 & 0\\\\\n",
       "\t 2 & 0\\\\\n",
       "\t 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 0 |\n",
       "| 2 | 0 |\n",
       "| 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 1    0   \n",
       "[2,] 2    0   \n",
       "[3,] 3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>2</td></tr>\n",
       "\t<tr><td>5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 1\\\\\n",
       "\t 2\\\\\n",
       "\t 5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 |\n",
       "| 2 |\n",
       "| 5 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] 1   \n",
       "[2,] 2   \n",
       "[3,] 5   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Equations..\n",
    "A = matrix(c(1, 2, 3, 0, 0, 1), ncol=2, byrow=F)\n",
    "b = matrix(c(1, 2, 5), ncol=1, byrow=F)\n",
    "A\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8cf3f32-950f-4bdd-a184-38891e12ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"pracma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2826a62b-b90b-49ed-9263-807c6ac7a07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in inv(t(A) %*% A): could not find function \"inv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in inv(t(A) %*% A): could not find function \"inv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Solving the equations, via least square method..\n",
    "x = inv( t(A) %*% A ) %*% t(A) %*% b\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcf1fa-a89e-48bd-8051-8c721a383491",
   "metadata": {},
   "source": [
    "### `case-3`: Where no. equations(m) < no. of variables(n) \n",
    "\n",
    "---- i.e., rows(m) < cols(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85d4c6-17cd-4110-acfc-9e6cc1f92fec",
   "metadata": {},
   "source": [
    "![](resources/case3Intro.png)\n",
    "\n",
    "**How to think this or understand this..??**\n",
    "> Consider 2 equations _(m=2)_ with 3 variables _(n=3)_, this can be thought as... \n",
    "    * **You could choose any value for $x_3$, plug in the 2 equations,, take them to R.H.S.*(as now they became constants)* and solve for rest $x_1 $ and $x_2$.**\n",
    "    * Here **one can choose infinite range of values for $x_3$**, Hence *Inifinite solutions*.. ---------------------making a clear sense right.. think for a while..\n",
    "\n",
    "****\n",
    "Now...if had infinite solutions.... ![](resources/case3Intro_1.png)\n",
    "> There is no way to distinguish between these infinite possible solutions, we need to have a metric -- with which we can pickup a solution.\n",
    "\n",
    "![](resources/case-3_Intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac83130-4117-4c9e-940b-e4aed53db6f3",
   "metadata": {},
   "source": [
    "An optimization perspective.. _(like the previous case...)_\n",
    "![](resources/case_3-OptimizationPerspective_1.png)\n",
    "* Notice the constraint: $Ax=b$ _(**s.t.:** subject-to)_. On an whole tells that: **Need to minimize $\\frac{1}{2}x^Tx$ subject to the constraint $Ax=b$**. \n",
    "    * In other words.... Whatever solution we get for $x$, has to satisfy the $Ax=b$. This is not the problem, as we have infinite no. of solutions. and what the $min \\left( \\frac{1}{2}x^Tx \\right)$ doing is... **How do I pick that one solution which minimizes the $x^Tx$**\n",
    "> $1/2$ is to make sure that, solution comes out in a nice form.\n",
    "\n",
    "**Engineering Perspective:**, Say you have many parameters for manufacturing, and you need only of the smallest cost/size...\n",
    "\n",
    "Unlike previous one, where there is no constraint, so its called :<mark>**Unconstrained Optimization**</mark>, here as there exists a constraint, its <mark>**Constrained Optimization**</mark>.\n",
    "\n",
    "![](resources/case3-OptimizationPerspective_1.png)\n",
    "![](resources/case3-OptimizationPerspective_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1193f14-89aa-44d0-878d-3db05425cf39",
   "metadata": {},
   "source": [
    "Example..\n",
    "![](resources/case3-OptimizationPerspective_Example_1.png)\n",
    "![](resources/case_3OptimizationPerspective_Example_2.png)\n",
    "Check...![](resources/case_3OptimizationPerspective_Example_3.png) -- <mark>Minimum Norm Solution</mark>\n",
    "****\n",
    "Workout...\n",
    "![](resources/DataScienceForEngineers_Week_2-SolvingLinearEquations_case_3-Module_3-ExampleWorkout.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0cb08a-2eea-4abc-b83c-d2bc902c69bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in inv(A %*% t(A)): could not find function \"inv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in inv(A %*% t(A)): could not find function \"inv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "A = matrix(c(01, 0, 2, 0, 3, 1), ncol=3, byrow=F)\n",
    "b = c(2, 1)\n",
    "x = t(A)  %*% inv(A  %*% t(A))  %*% b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe706af-88c1-4067-a367-e656e1ba9111",
   "metadata": {},
   "source": [
    "Till now, we came across, different methods for different case right.., **Is there any generalized method, with which one can solve all the cases** _(whether square [m==n] or rectangle [m!=n: $m<n$ or $m>n$])_ --- Yes.. its <mark>**Moore-Penrose pseudo-inverse matrix**</mark>\n",
    "![](resources/case_3OptimizationPerspective_generalization_Pseudo_Inverse_Matrix.png) -- here $x=A^{-1}b$ is the solution which we were used to do in previous cases, now this way...\n",
    "\n",
    "* There are many ways to compute pseudo-inverse, <mark>SVD-Singular Value Decomposition</mark> is one of the method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "118d500c-923b-4aaa-abb2-89e0147172b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>2</td><td>0</td></tr>\n",
       "\t<tr><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t 1 & 0\\\\\n",
       "\t 2 & 0\\\\\n",
       "\t 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 0 |\n",
       "| 2 | 0 |\n",
       "| 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 1    0   \n",
       "[2,] 2    0   \n",
       "[3,] 3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>2</td></tr>\n",
       "\t<tr><td>5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 1\\\\\n",
       "\t 2\\\\\n",
       "\t 5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 |\n",
       "| 2 |\n",
       "| 5 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] 1   \n",
       "[2,] 2   \n",
       "[3,] 5   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = matrix( c(1, 2, 3, 0, 0, 1), ncol=2, byrow=F)\n",
    "b = matrix(c(1, 2, 5), ncol=1, byrow=F)\n",
    "A\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c319e4-77dd-42ee-af38-f7ad2618bf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 1\\\\\n",
       "\t 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 |\n",
       "| 2 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] 1   \n",
       "[2,] 2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the pseudo-inverse of the matrix..  which is of more variables than equations ... m<n case..\n",
    "library(MASS)\n",
    "x = ginv(A) %*% b   # Here 'g' in \"ginv\" stands for \"\"\"Generalization\"\"\"\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e006dc-1976-4f50-9a4f-4ae01aec5671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>2</td><td>3</td></tr>\n",
       "\t<tr><td>0</td><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       "\t 1 & 2 & 3\\\\\n",
       "\t 0 & 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 2 | 3 |\n",
       "| 0 | 0 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3]\n",
       "[1,] 1    2    3   \n",
       "[2,] 0    0    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = matrix( c(1, 0, 2, 0, 3, 1), ncol=3, byrow=F)\n",
    "b = c(2, 1)\n",
    "A\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7acb27fa-edbd-4bf8-8cf6-1e652c1a777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>-0.2</td></tr>\n",
       "\t<tr><td>-0.4</td></tr>\n",
       "\t<tr><td> 1.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t -0.2\\\\\n",
       "\t -0.4\\\\\n",
       "\t  1.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| -0.2 |\n",
       "| -0.4 |\n",
       "|  1.0 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]\n",
       "[1,] -0.2\n",
       "[2,] -0.4\n",
       "[3,]  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the pseudo-inverse of the matrix..  which is of more equations than variables ...m>n case..\n",
    "library(MASS)\n",
    "x = ginv(A) %*% b\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c3f0c-6fa6-4241-a705-5b1b89d411e9",
   "metadata": {},
   "source": [
    "The values of $x$ can be calculated via these... **How to interpret those....??**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78930b4d-562b-4a25-a5d4-8c7ce392741d",
   "metadata": {},
   "source": [
    "That's what done in the lecture..\n",
    "* For the case of $m>n$, its the solution: **Least Square Solution**_(which minimizes the error collectively)_  i.e., minimizes $e_1^2 + e_2^2 + e_3^2 .....$\n",
    "* For the case of $m<n$,  --- Minimum norm solution, this is the solution that is closest to the originm when had infinite no. of solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f65de-5167-4334-92fc-c93044bbc33f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c373b-da30-47b9-9dd3-6e15a6da6d02",
   "metadata": {},
   "source": [
    "![](resources/solvingLinearEquations_Summary.png)\n",
    "\n",
    "So, without worrying about the square or rectangular system and not worrying about, whether the columns are dependent or independent, we can use generalized solution as one unify concept to find the solution to all the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b53d0b-0784-41b7-ba98-aba6c9d2b33a",
   "metadata": {},
   "source": [
    "Coming up next...\n",
    "* Geometrical View of these.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
